{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm import tqdm\nfrom numpy import asarray\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n#from keras.applications.resnet import ResNet50\n#from keras.applications.resnet import ResNet50\nfrom tensorflow.keras.applications.resnet import decode_predictions\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.layers import Input,UpSampling2D,Flatten,BatchNormalization,Dense,Dropout,GlobalAveragePooling2D\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom glob import glob\nfrom PIL import Image\nimport pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-02-25T07:41:01.841924Z","iopub.execute_input":"2023-02-25T07:41:01.843057Z","iopub.status.idle":"2023-02-25T07:41:09.622074Z","shell.execute_reply.started":"2023-02-25T07:41:01.843008Z","shell.execute_reply":"2023-02-25T07:41:09.620799Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"#  **Implimenting ResNET50 ARCH**","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = [512, 512]\n\ntrain_path = '/kaggle/input/lung-cancer-dataset/Lung cancer dataset/train'\nval_path = '/kaggle/input/lung-cancer-dataset/Lung cancer dataset/val'\n\nfolders = glob(train_path+'/*')\nprint(\"Number of classes:\",len(folders))\nnum_classes = len(folders)\nnb_epochs = 30\n\nresnet=ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n# Fixed for our dataset\nNUM_CLASSES = num_classes\n\n# Fixed for Cats & Dogs color images\nCHANNELS = 3\n\nIMAGE_RESIZE = 512\nRESNET50_POOLING_AVERAGE = 'avg'\nDENSE_LAYER_ACTIVATION = 'softmax'\nOBJECTIVE_FUNCTION = 'categorical_crossentropy'\n\n# Common accuracy metric for all outputs, but can use different metrics for different output\nLOSS_METRICS = ['accuracy']\n\n# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n#NUM_EPOCHS = 60\n#EARLY_STOP_PATIENCE = 3\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\nSTEPS_PER_EPOCH_TRAINING = 10\nSTEPS_PER_EPOCH_VALIDATION = 2\n\n# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\nBATCH_SIZE_TRAINING =64\nBATCH_SIZE_VALIDATION =32\n\nfrom tensorflow.keras.models import Model,Sequential\nmodel4 = Sequential()\n\n# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\nmodel4.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = 'imagenet'))\n\n# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\nmodel4.add(Dense(num_classes, activation = 'softmax'))\n\n# Say not to train first layer (ResNet) model as it is already trained\nmodel4.layers[0].trainable = False\n\nmodel4.summary()\n\nfrom tensorflow.keras import optimizers\n\nsgd = optimizers.SGD(learning_rate = 0.001, momentum = 0.9, nesterov = True)\nmodel4.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)\n\n\n\n\n\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = IMAGE_RESIZE\n\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = data_generator.flow_from_directory(\n        train_path,\n        target_size=(image_size, image_size),\n        batch_size=BATCH_SIZE_TRAINING,\n        class_mode='categorical')\n\n\nvalidation_generator = data_generator.flow_from_directory(\n        val_path,\n        target_size=(image_size, image_size),\n        batch_size=BATCH_SIZE_VALIDATION,\n        class_mode='categorical')\n\nhistory = model4.fit(\n        train_generator,\n        epochs = nb_epochs,\n        validation_data=validation_generator#,\n    #steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n    #validation_steps=STEPS_PER_EPOCH_VALIDATION\n        \n        )\n\nmodel4.save(\"SGD_trial_1.1_classification_using_resnet50.h5\")\nprint(\"Saved model to disk\")\n\ndf = pd.DataFrame(history.history)\ndf.to_csv('SGD_trial_1.1_Resnet50history.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T08:13:12.078877Z","iopub.execute_input":"2023-02-25T08:13:12.079319Z","iopub.status.idle":"2023-02-25T08:23:32.196313Z","shell.execute_reply.started":"2023-02-25T08:13:12.079283Z","shell.execute_reply":"2023-02-25T08:23:32.195080Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of classes: 3\nModel: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n resnet50 (Functional)       (None, 2048)              23587712  \n                                                                 \n dense_2 (Dense)             (None, 3)                 6147      \n                                                                 \n=================================================================\nTotal params: 23,593,859\nTrainable params: 6,147\nNon-trainable params: 23,587,712\n_________________________________________________________________\nFound 950 images belonging to 3 classes.\nFound 134 images belonging to 3 classes.\nEpoch 1/30\n15/15 [==============================] - 25s 1s/step - loss: 0.7366 - accuracy: 0.7400 - val_loss: 0.5235 - val_accuracy: 0.8881\nEpoch 2/30\n15/15 [==============================] - 20s 1s/step - loss: 0.4100 - accuracy: 0.8642 - val_loss: 0.4140 - val_accuracy: 0.8806\nEpoch 3/30\n15/15 [==============================] - 20s 1s/step - loss: 0.3495 - accuracy: 0.8674 - val_loss: 0.3817 - val_accuracy: 0.8657\nEpoch 4/30\n15/15 [==============================] - 20s 1s/step - loss: 0.3218 - accuracy: 0.8674 - val_loss: 0.3521 - val_accuracy: 0.8731\nEpoch 5/30\n15/15 [==============================] - 20s 1s/step - loss: 0.3042 - accuracy: 0.8695 - val_loss: 0.3491 - val_accuracy: 0.8657\nEpoch 6/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2920 - accuracy: 0.8716 - val_loss: 0.3684 - val_accuracy: 0.8806\nEpoch 7/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2836 - accuracy: 0.8800 - val_loss: 0.3263 - val_accuracy: 0.8657\nEpoch 8/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2715 - accuracy: 0.8821 - val_loss: 0.3242 - val_accuracy: 0.8582\nEpoch 9/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2636 - accuracy: 0.8800 - val_loss: 0.3217 - val_accuracy: 0.8582\nEpoch 10/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2573 - accuracy: 0.8821 - val_loss: 0.3218 - val_accuracy: 0.8582\nEpoch 11/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2480 - accuracy: 0.8895 - val_loss: 0.3213 - val_accuracy: 0.8582\nEpoch 12/30\n15/15 [==============================] - 23s 2s/step - loss: 0.2407 - accuracy: 0.8874 - val_loss: 0.3224 - val_accuracy: 0.8657\nEpoch 13/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2351 - accuracy: 0.8937 - val_loss: 0.3246 - val_accuracy: 0.8657\nEpoch 14/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2302 - accuracy: 0.8937 - val_loss: 0.3214 - val_accuracy: 0.8657\nEpoch 15/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2235 - accuracy: 0.9000 - val_loss: 0.3268 - val_accuracy: 0.8806\nEpoch 16/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2198 - accuracy: 0.9011 - val_loss: 0.3471 - val_accuracy: 0.8806\nEpoch 17/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2148 - accuracy: 0.9158 - val_loss: 0.3050 - val_accuracy: 0.8657\nEpoch 18/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2115 - accuracy: 0.9063 - val_loss: 0.3515 - val_accuracy: 0.8731\nEpoch 19/30\n15/15 [==============================] - 22s 1s/step - loss: 0.2107 - accuracy: 0.9126 - val_loss: 0.3054 - val_accuracy: 0.8657\nEpoch 20/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2030 - accuracy: 0.9168 - val_loss: 0.3058 - val_accuracy: 0.8657\nEpoch 21/30\n15/15 [==============================] - 20s 1s/step - loss: 0.2007 - accuracy: 0.9158 - val_loss: 0.3053 - val_accuracy: 0.8657\nEpoch 22/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1964 - accuracy: 0.9126 - val_loss: 0.3060 - val_accuracy: 0.8657\nEpoch 23/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1910 - accuracy: 0.9211 - val_loss: 0.3226 - val_accuracy: 0.8955\nEpoch 24/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1886 - accuracy: 0.9168 - val_loss: 0.3426 - val_accuracy: 0.8806\nEpoch 25/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1874 - accuracy: 0.9347 - val_loss: 0.3141 - val_accuracy: 0.8955\nEpoch 26/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1823 - accuracy: 0.9295 - val_loss: 0.3164 - val_accuracy: 0.8955\nEpoch 27/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1800 - accuracy: 0.9284 - val_loss: 0.3279 - val_accuracy: 0.8881\nEpoch 28/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1784 - accuracy: 0.9347 - val_loss: 0.3209 - val_accuracy: 0.8955\nEpoch 29/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1753 - accuracy: 0.9337 - val_loss: 0.3414 - val_accuracy: 0.8806\nEpoch 30/30\n15/15 [==============================] - 20s 1s/step - loss: 0.1722 - accuracy: 0.9305 - val_loss: 0.3411 - val_accuracy: 0.8806\nSaved model to disk\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Predication**","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import load_model\n\n# Load the model from the H5 file\nmodel = load_model('/kaggle/input/lcr50-weights/SGD_trial_1_classification_using_resnet50.h5')\n\nDIRECTORY= \"/kaggle/input/lung-cancer-dataset/Lung cancer dataset/test\"\nclass_names=['Bengin case','Malignant case','Normal case']\n\ndata = {'class': [],\n        'predicate_class': [],\n        'status': []}\npcount=0\nfcount=0\ntotalb=totalm=totaln=fb=fm=fn=0.0\ndf = pd.DataFrame(data)\nfor img in os.listdir(DIRECTORY):\n    img_path=os.path.join(DIRECTORY,img)\n    img_array=cv2.imread(img_path)\n    img_array=cv2.resize(img_array,(512,512))\n    img_array_=img_array\n    img_array_=np.expand_dims(img_array_,axis=0)\n    pred=model.predict(np.array(img_array_))\n    output_class=class_names[np.argmax(pred)]\n    s=img.split()\n    ctemp=s[0]+\" \"+s[1]\n    if(ctemp=='Bengin case'):\n        totalb=totalb+1\n    if(ctemp=='Malignant case'):\n        totalm=totalm+1\n    if(ctemp=='Normal case'):\n        totaln=totaln+1\n    if(ctemp==output_class):\n        temp = {'class': ctemp, 'predicate_class': output_class , 'status':'pass'}\n        pcount=pcount+1\n        df = df.append(temp, ignore_index=True)\n    else :\n        temp = {'class': ctemp, 'predicate_class': output_class , 'status':'fail'}\n        fcount=fcount+1\n        df = df.append(temp, ignore_index=True)\n\n        if(ctemp=='Bengin case'):\n            fb=fb+1\n        if(ctemp=='Malignant case'):\n            fm=fm+1\n        if(ctemp=='Normal case'):\n            fn=fn+1\nprint(\"Predication Accuracy of each class\")\nprint('Bengin case',(((totalb-fb)/totalb)*100))\nprint('Malignant case',(((totalm-fm)/totalm)*100))\nprint('Normal case',(((totaln-fn)/totaln)*100))\nprint(\"Predication Accuracy of the model is \",(pcount/(pcount+fcount)*100))\nprint(\"Pass count=\",pcount)\nprint(\"Fail count=\",fcount)\ndf\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-26T15:22:15.574375Z","iopub.execute_input":"2023-02-26T15:22:15.574771Z","iopub.status.idle":"2023-02-26T15:22:37.833431Z","shell.execute_reply.started":"2023-02-26T15:22:15.574723Z","shell.execute_reply":"2023-02-26T15:22:37.832227Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 2s 2s/step\n1/1 [==============================] - 1s 521ms/step\n1/1 [==============================] - 0s 495ms/step\n1/1 [==============================] - 0s 436ms/step\n1/1 [==============================] - 0s 475ms/step\n1/1 [==============================] - 0s 474ms/step\n1/1 [==============================] - 0s 468ms/step\n1/1 [==============================] - 0s 471ms/step\n1/1 [==============================] - 0s 499ms/step\n1/1 [==============================] - 0s 467ms/step\n1/1 [==============================] - 0s 473ms/step\n1/1 [==============================] - 0s 474ms/step\n1/1 [==============================] - 0s 482ms/step\nPredication Accuracy of each class\nBengin case 20.0\nMalignant case 100.0\nNormal case 100.0\nPredication Accuracy of the model is  69.23076923076923\nPass count= 9\nFail count= 4\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"             class predicate_class status\n0      Normal case     Normal case   pass\n1   Malignant case  Malignant case   pass\n2   Malignant case  Malignant case   pass\n3      Bengin case     Bengin case   pass\n4      Bengin case     Normal case   fail\n5      Bengin case     Normal case   fail\n6   Malignant case  Malignant case   pass\n7      Bengin case     Normal case   fail\n8      Normal case     Normal case   pass\n9   Malignant case  Malignant case   pass\n10     Normal case     Normal case   pass\n11     Bengin case     Normal case   fail\n12     Normal case     Normal case   pass","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>predicate_class</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Normal case</td>\n      <td>Normal case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Malignant case</td>\n      <td>Malignant case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Malignant case</td>\n      <td>Malignant case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bengin case</td>\n      <td>Bengin case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bengin case</td>\n      <td>Normal case</td>\n      <td>fail</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Bengin case</td>\n      <td>Normal case</td>\n      <td>fail</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Malignant case</td>\n      <td>Malignant case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Bengin case</td>\n      <td>Normal case</td>\n      <td>fail</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Normal case</td>\n      <td>Normal case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Malignant case</td>\n      <td>Malignant case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Normal case</td>\n      <td>Normal case</td>\n      <td>pass</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Bengin case</td>\n      <td>Normal case</td>\n      <td>fail</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Normal case</td>\n      <td>Normal case</td>\n      <td>pass</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv('SGDdata.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T14:02:51.833911Z","iopub.execute_input":"2023-02-26T14:02:51.834453Z","iopub.status.idle":"2023-02-26T14:02:51.847801Z","shell.execute_reply.started":"2023-02-26T14:02:51.834405Z","shell.execute_reply":"2023-02-26T14:02:51.846299Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}